{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e16d58b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "HOME = os.path.abspath('..')\n",
    "sys.path.append(HOME)\n",
    "os.chdir(HOME)\n",
    "import torchvision\n",
    "import dlib\n",
    "from PIL import Image\n",
    "from imutils import face_utils\n",
    "from src.data.dataprep_mediapipe import *\n",
    "from src.data.imgutils import *\n",
    "from src.features.features_extractors_mediapipe import *\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from vidstab import VidStab\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "045f403f",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = cv2.VideoCapture('data/raw/3_face_smile.MOV')\n",
    "a=[]\n",
    "while True:\n",
    "    ret, frame = v.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "    a.append(cv2.cvtColor(frame,cv2.COLOR_BGR2RGB))\n",
    "video = np.array(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2964bad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = pd.read_pickle('data/processed/29_face_smile.pkl')\n",
    "video = [i['frame'] for i in v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "21ec5f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "stabilizer = VidStab()\n",
    "stabilizer.stabilize(input_path='data/raw/3_face_smile.MOV', output_path='data/raw/3_face_smile_stable.MOV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "16b956dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "v_s = cv2.VideoCapture('data/raw/3_face_smile_stable.MOV')\n",
    "a_s=[]\n",
    "while True:\n",
    "    ret, frame = v_s.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "    a_s.append(cv2.cvtColor(frame,cv2.COLOR_BGR2RGB))\n",
    "video = np.array(a_s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e88f347e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-70662fbe72d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m     flow = cv.calcOpticalFlowFarneback(prev_gray, gray,\n\u001b[1;32m     50\u001b[0m                                     \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                                     0.5, 3, 15, 3, 5, 1.2, 0)\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# Computes the magnitude and angle of the 2D vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# The video feed is read in as\n",
    "# a VideoCapture object\n",
    "#cap = cv.VideoCapture('../data/dummy_data/samir/face_smile_sequence.mp4')\n",
    "\n",
    "# ret = a boolean return value from\n",
    "# getting the frame, first_frame = the\n",
    "# first frame in the entire video sequence\n",
    "first_frame = video[0]\n",
    "\n",
    "#first_frame = cv2.resize(first_frame,(360,480))\n",
    "\n",
    "# Converts frame to grayscale because we\n",
    "# only need the luminance channel for\n",
    "# detecting edges - less computationally\n",
    "# expensive\n",
    "prev_gray = cv.cvtColor(first_frame, cv.COLOR_RGB2GRAY)\n",
    "\n",
    "#prev_gray = clahe.apply(prev_gray)\n",
    "\n",
    "# Creates an image filled with zero\n",
    "# intensities with the same dimensions\n",
    "# as the frame\n",
    "mask = np.zeros_like(first_frame)\n",
    "\n",
    "# Sets image saturation to maximum\n",
    "mask[..., 1] = 255\n",
    "\n",
    "for frame in video[1:]:\n",
    "    \n",
    "    # ret = a boolean return value from getting\n",
    "    # the frame, frame = the current frame being\n",
    "    # projected in the video\n",
    "\n",
    "    # Opens a new window and displays the input\n",
    "    #frame = cv2.resize(frame,(360,480))\n",
    "\n",
    "    cv.imshow(\"input\", frame)\n",
    "    \n",
    "    # Converts each frame to grayscale - we previously\n",
    "    # only converted the first frame to grayscale\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_RGB2GRAY)\n",
    "    #gray = clahe.apply(gray)\n",
    "    \n",
    "    # Calculates dense optical flow by Farneback method\n",
    "    flow = cv.calcOpticalFlowFarneback(prev_gray, gray,\n",
    "                                    None,\n",
    "                                    0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "    \n",
    "    # Computes the magnitude and angle of the 2D vectors\n",
    "    magnitude, angle = cv.cartToPolar(flow[..., 0], flow[..., 1])\n",
    "    \n",
    "    # Sets image hue according to the optical flow\n",
    "    # direction\n",
    "    mask[..., 0] = angle * 180 / np.pi / 2\n",
    "    \n",
    "    # Sets image value according to the optical flow\n",
    "    # magnitude (normalized)\n",
    "    mask[..., 2] = cv.normalize(magnitude, None, 0, 255, cv.NORM_MINMAX)\n",
    "    \n",
    "    # Converts HSV to RGB (BGR) color representation\n",
    "    rgb = cv.cvtColor(mask, cv.COLOR_HSV2BGR)\n",
    "    \n",
    "    # Opens a new window and displays the output frame\n",
    "    cv.imshow(\"dense optical flow\", rgb)\n",
    "    \n",
    "    # Updates previous frame\n",
    "    prev_gray = gray\n",
    "    \n",
    "    # Frames are read by intervals of 1 millisecond. The\n",
    "    # programs breaks out of the while loop when the\n",
    "    # user presses the 'q' key\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f06e585d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 1280, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret, first_frame = cap.read()\n",
    "\n",
    "first_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24b581ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(360.0, 640.0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "720/2,1280/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "092aeee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.OPTFLOW_FARNEBACK_GAUSSIAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d3c8c18",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) :-1: error: (-5:Bad argument) in function 'line'\n> Overload resolution failed:\n>  - Can't parse 'pt1'. Sequence item with index 0 has a wrong type\n>  - Can't parse 'pt1'. Sequence item with index 0 has a wrong type\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e6f439305a9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \t\tmask = cv2.line(mask, (a, b), (c, d),\n\u001b[0;32m---> 53\u001b[0;31m \t\t\t\t\t\tcolor[i].tolist(), 2)\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \t\tframe = cv2.circle(frame, (a, b), 5,\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.5) :-1: error: (-5:Bad argument) in function 'line'\n> Overload resolution failed:\n>  - Can't parse 'pt1'. Sequence item with index 0 has a wrong type\n>  - Can't parse 'pt1'. Sequence item with index 0 has a wrong type\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# params for corner detection\n",
    "feature_params = dict( maxCorners = 100,\n",
    "\t\t\t\t\tqualityLevel = 0.3,\n",
    "\t\t\t\t\tminDistance = 7,\n",
    "\t\t\t\t\tblockSize = 7 )\n",
    "\n",
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict( winSize = (15, 15),\n",
    "\t\t\t\tmaxLevel = 2,\n",
    "\t\t\t\tcriteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,\n",
    "\t\t\t\t\t\t\t10, 0.03))\n",
    "\n",
    "# Create some random colors\n",
    "color = np.random.randint(0, 255, (100, 3))\n",
    "\n",
    "# Take first frame and find corners in it\n",
    "ret, old_frame = cap.read()\n",
    "old_gray = cv2.cvtColor(old_frame,\n",
    "\t\t\t\t\t\tcv2.COLOR_BGR2GRAY)\n",
    "p0 = cv2.goodFeaturesToTrack(old_gray, mask = None,\n",
    "\t\t\t\t\t\t\t**feature_params)\n",
    "\n",
    "# Create a mask image for drawing purposes\n",
    "mask = np.zeros_like(old_frame)\n",
    "\n",
    "while(1):\n",
    "\t\n",
    "\tret, frame = cap.read()\n",
    "\tframe_gray = cv2.cvtColor(frame,\n",
    "\t\t\t\t\t\t\tcv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\t# calculate optical flow\n",
    "\tp1, st, err = cv2.calcOpticalFlowPyrLK(old_gray,\n",
    "\t\t\t\t\t\t\t\t\t\tframe_gray,\n",
    "\t\t\t\t\t\t\t\t\t\tp0, None,\n",
    "\t\t\t\t\t\t\t\t\t\t**lk_params)\n",
    "\n",
    "\t# Select good points\n",
    "\tgood_new = p1[st == 1]\n",
    "\tgood_old = p0[st == 1]\n",
    "\n",
    "\t# draw the tracks\n",
    "\tfor i, (new, old) in enumerate(zip(good_new,\n",
    "\t\t\t\t\t\t\t\t\tgood_old)):\n",
    "\t\ta, b = new.ravel()\n",
    "\t\tc, d = old.ravel()\n",
    "\t\tmask = cv2.line(mask, (a, b), (c, d),\n",
    "\t\t\t\t\t\tcolor[i].tolist(), 2)\n",
    "\t\t\n",
    "\t\tframe = cv2.circle(frame, (a, b), 5,\n",
    "\t\t\t\t\t\tcolor[i].tolist(), -1)\n",
    "\t\t\n",
    "\timg = cv2.add(frame, mask)\n",
    "\n",
    "\tcv2.imshow('frame', img)\n",
    "\t\n",
    "\tk = cv2.waitKey(25)\n",
    "\tif k == 27:\n",
    "\t\tbreak\n",
    "\n",
    "\t# Updating Previous frame and points\n",
    "\told_gray = frame_gray.copy()\n",
    "\tp0 = good_new.reshape(-1, 1, 2)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9756d9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# get flownet2-pytorch source\n",
    "!git clone https://github.com/Gauravv97/flownet2-pytorch.git\n",
    "!mv /content/flownet2-pytorch /content/flownet2pytorch\n",
    "os.chdir('./flownet2pytorch')\n",
    "# install custom layers\n",
    "!bash install.sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
